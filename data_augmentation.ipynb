{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Obtaining dependency information for imbalanced-learn from https://files.pythonhosted.org/packages/9d/41/721fec82606242a2072ee909086ff918dfad7d0199a9dfd4928df9c72494/imbalanced_learn-0.13.0-py3-none-any.whl.metadata\n",
      "  Downloading imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\polin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\polin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.11.3)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\polin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.5.0)\n",
      "Collecting sklearn-compat<1,>=0.1 (from imbalanced-learn)\n",
      "  Obtaining dependency information for sklearn-compat<1,>=0.1 from https://files.pythonhosted.org/packages/f0/a8/ad69cf130fbd017660cdd64abbef3f28135d9e2e15fe3002e03c5be0ca38/sklearn_compat-0.1.3-py3-none-any.whl.metadata\n",
      "  Downloading sklearn_compat-0.1.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\polin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\polin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Downloading imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
      "   ---------------------------------------- 0.0/238.4 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 30.7/238.4 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------- ---------------------------- 61.4/238.4 kB 825.8 kB/s eta 0:00:01\n",
      "   -------------------- ------------------- 122.9/238.4 kB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 204.8/238.4 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 238.4/238.4 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: sklearn-compat, imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.13.0 sklearn-compat-0.1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Obtaining dependency information for tqdm from https://files.pythonhosted.org/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
      "     ------- -------------------------------- 10.2/57.7 kB ? eta -:--:--\n",
      "     -------------------------- ----------- 41.0/57.7 kB 487.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 57.7/57.7 kB 431.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\polin\\appdata\\roaming\\python\\python311\\site-packages (from tqdm) (0.4.6)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ------------------------------- -------- 61.4/78.5 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 78.5/78.5 kB 1.5 MB/s eta 0:00:00\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from imblearn.over_sampling import RandomOverSampler, SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# INITIAL_IMAGE_DIRECTORY = \"one_eye_images_copy\"\n",
    "# DESTINATION_DIRECTORY = \"one_eye_images_copy\"\n",
    "\n",
    "def augment_image(image_name, input_path, output_path, transform, n_augments=5):\n",
    "    image = Image.open(os.path.join(input_path, image_name), 'r')\n",
    "    augmented_image_names = []\n",
    "    \n",
    "    for i in range(n_augments):\n",
    "        aug_image = transform(image)\n",
    "        aug_image_name = image_name.split('.')[0] + f\"_aug{i}.jpg\"\n",
    "        aug_image_path = os.path.join(output_path, aug_image_name)\n",
    "        aug_image.save(aug_image_path)\n",
    "        augmented_image_names.append(aug_image_name)\n",
    "    \n",
    "    return augmented_image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_dataset(dataset, target_samples, disease_columns, input_path, image_output_path, df_output_path=\"\", transform=None):\n",
    "    if not transform:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.5, contrast=0.2, saturation=0.2, hue=0),\n",
    "            transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5))\n",
    "            ])\n",
    "    \n",
    "    if not os.path.exists(image_output_path):\n",
    "        os.makedirs(image_output_path)\n",
    "    \n",
    "    augmented_data = []\n",
    "    \n",
    "    for disease in disease_columns:\n",
    "        group = dataset[dataset[disease] == 1]\n",
    "        n_augments = target_samples - len(group)\n",
    "        augments_per_image = n_augments // len(group)\n",
    "        if augments_per_image == 0:\n",
    "            augments_per_image += 1\n",
    "        augmented = 0\n",
    "        progress_bar = tqdm(total=n_augments, desc=f\"Augmenting {disease}\", initial=0)\n",
    "        for _, row in group.iterrows():\n",
    "            if augmented == n_augments:\n",
    "                break\n",
    "            augmented_image_names = augment_image(row['image_id'], input_path, image_output_path, transform, augments_per_image)\n",
    "            for aug_image_name in augmented_image_names:\n",
    "                augmented_data.append({\n",
    "                    'image_id': aug_image_name,\n",
    "                    'patient_age': row['patient_age'],\n",
    "                    'patient_sex': row['patient_sex'],\n",
    "                    **{col: row[col] for col in disease_columns}\n",
    "                })\n",
    "                augmented += 1\n",
    "                progress_bar.update(1)\n",
    "        while augmented < n_augments:\n",
    "            for _, row in group.iterrows():\n",
    "                if augmented == n_augments:\n",
    "                    break\n",
    "                augmented_image_names = augment_image(row['image_id'], input_path, image_output_path, transform, 1)\n",
    "                for aug_image_name in augmented_image_names:\n",
    "                    augmented_data.append({\n",
    "                        'image_id': aug_image_name,\n",
    "                        'patient_age': row['patient_age'],\n",
    "                        'patient_sex': row['patient_sex'],\n",
    "                        **{col: row[col] for col in disease_columns}\n",
    "                    })\n",
    "                    augmented += 1\n",
    "                    progress_bar.update(1)\n",
    "    augmented_dataframe = pd.DataFrame(augmented_data)\n",
    "    augmented_dataframe.to_csv(os.path.join(df_output_path, \"augmented_df.csv\"))\n",
    "    return augmented_dataframe\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
